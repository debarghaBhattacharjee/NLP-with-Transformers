{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlw007W6IBxrHFg9MjekTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f76d008f29c244568d8cae0c93162d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_031ab5cd22bd4ad5a752d68d042c9feb",
              "IPY_MODEL_7bc5cfd68c624e33894aa592f7c553c7",
              "IPY_MODEL_262db55c3a3a4b0e9dcf5a6b414b1971"
            ],
            "layout": "IPY_MODEL_1179608a014847559efb3ab1ef285bb0"
          }
        },
        "031ab5cd22bd4ad5a752d68d042c9feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644a6efb7ece4df2a6ff959520f30d8c",
            "placeholder": "​",
            "style": "IPY_MODEL_9c1f1ea9445e472aa2af4fcfa053ad7e",
            "value": "100%"
          }
        },
        "7bc5cfd68c624e33894aa592f7c553c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e5c27ff24f4f2e97efc292a5e42c85",
            "max": 76,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a4a2ebc16ac4e3189796ce691921989",
            "value": 76
          }
        },
        "262db55c3a3a4b0e9dcf5a6b414b1971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d48f22042cb447298ca50b1376b855f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1b687491934eb9b6ce1bbc7b1c8f3b",
            "value": " 76/76 [00:09&lt;00:00,  9.13ba/s]"
          }
        },
        "1179608a014847559efb3ab1ef285bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644a6efb7ece4df2a6ff959520f30d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1f1ea9445e472aa2af4fcfa053ad7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e5c27ff24f4f2e97efc292a5e42c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4a2ebc16ac4e3189796ce691921989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d48f22042cb447298ca50b1376b855f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1b687491934eb9b6ce1bbc7b1c8f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5913127fa947848288a7041007a0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27b6e64ac8f345e8a7dd116c6e58b752",
              "IPY_MODEL_e544b40993fc4124b6a90278ca9c980a",
              "IPY_MODEL_39f211468fea4aa4a08770b7c9bf2653"
            ],
            "layout": "IPY_MODEL_df6b9d6b6163451bb82f44c2b94e4c33"
          }
        },
        "27b6e64ac8f345e8a7dd116c6e58b752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7e611399de44a3bde37379caecf99c",
            "placeholder": "​",
            "style": "IPY_MODEL_3983ba42251741bf9dbd84e0c6eebc01",
            "value": "100%"
          }
        },
        "e544b40993fc4124b6a90278ca9c980a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9350d2518e1e4e2088f163fed0976b72",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7832d55edb694132af5b56f2c864fe0b",
            "value": 11
          }
        },
        "39f211468fea4aa4a08770b7c9bf2653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10f7f5990d224bc5936f847979f67598",
            "placeholder": "​",
            "style": "IPY_MODEL_d74748499b1f4d7fb5c0e2444082ba4e",
            "value": " 11/11 [00:01&lt;00:00,  7.29ba/s]"
          }
        },
        "df6b9d6b6163451bb82f44c2b94e4c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7e611399de44a3bde37379caecf99c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3983ba42251741bf9dbd84e0c6eebc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9350d2518e1e4e2088f163fed0976b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7832d55edb694132af5b56f2c864fe0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10f7f5990d224bc5936f847979f67598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74748499b1f4d7fb5c0e2444082ba4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dea78ccd64b4c84b1ab70348d56d37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_106fec184be54b25970e7e9f466fee59",
              "IPY_MODEL_38a3cfc23ce84fb19886dee129176ab8",
              "IPY_MODEL_4dc1d3d43f514315a97e586ca4d055c1"
            ],
            "layout": "IPY_MODEL_abccacaaa1b74757b17938498db2848d"
          }
        },
        "106fec184be54b25970e7e9f466fee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_032b8f29caf44a80bd3ed6d8b6e718fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b81a6dae8ba149afb42938ac129482a9",
            "value": "100%"
          }
        },
        "38a3cfc23ce84fb19886dee129176ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219e6189258c4190bedab2d06c9504a5",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50fb956b9a26493c840cbd5c746be5e0",
            "value": 12
          }
        },
        "4dc1d3d43f514315a97e586ca4d055c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ee86b8a2e842019f96849f4b01a7a9",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3c6d3bdf3b4b23be55f33d88ba0e95",
            "value": " 12/12 [00:01&lt;00:00,  8.70ba/s]"
          }
        },
        "abccacaaa1b74757b17938498db2848d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032b8f29caf44a80bd3ed6d8b6e718fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81a6dae8ba149afb42938ac129482a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219e6189258c4190bedab2d06c9504a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50fb956b9a26493c840cbd5c746be5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ee86b8a2e842019f96849f4b01a7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3c6d3bdf3b4b23be55f33d88ba0e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debarghaBhattacharjee/NLP-with-Transformers/blob/main/automatic_question_generation/aqg_with_trainer_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucQYL2xzhXh_"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "vLjji-3xhopj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading dataset from Hub"
      ],
      "metadata": {
        "id": "X5gq4sW0kWuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "D2hsB5n4h1YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"lmqg/qg_squad\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "WzBC_qZFiROj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHOPKi_tizNQ",
        "outputId": "b5c4ad77-40dd-4dbe-858d-870afceb4ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'established beliefs or customs',\n",
              " 'question': 'What is heresy mainly at odds with?',\n",
              " 'sentence': 'Heresy is any provocative belief or theory that is strongly at variance with established beliefs or customs .',\n",
              " 'paragraph': \"Heresy is any provocative belief or theory that is strongly at variance with established beliefs or customs. A heretic is a proponent of such claims or beliefs. Heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning God or sacred things.\",\n",
              " 'sentence_answer': 'Heresy is any provocative belief or theory that is strongly at variance with <hl> established beliefs or customs <hl> .',\n",
              " 'paragraph_answer': \"Heresy is any provocative belief or theory that is strongly at variance with <hl> established beliefs or customs <hl>. A heretic is a proponent of such claims or beliefs. Heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning God or sacred things.\",\n",
              " 'paragraph_sentence': \"<hl> Heresy is any provocative belief or theory that is strongly at variance with established beliefs or customs . <hl> A heretic is a proponent of such claims or beliefs. Heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning God or sacred things.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_8Lj-s-jBhj",
        "outputId": "6ff5377d-9091-408e-8d29-d2b9a4ca36c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'sentence': Value(dtype='string', id=None),\n",
              " 'paragraph': Value(dtype='string', id=None),\n",
              " 'sentence_answer': Value(dtype='string', id=None),\n",
              " 'paragraph_answer': Value(dtype='string', id=None),\n",
              " 'paragraph_sentence': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing a dataset"
      ],
      "metadata": {
        "id": "BZeYv1m_kZLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "bkaMvHLukKAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"lmqg/t5-small-squad\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "4QBUaCTkki-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"this is the first sentence\", \"this is the second sentence\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eelNtDLEkqK4",
        "outputId": "a9269c75-20d2-4271-97a7-a0e58a8d7d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [48, 19, 8, 166, 7142, 1, 48, 19, 8, 511, 7142, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZY9jMzZlZOk",
        "outputId": "e326db1b-03fc-47a1-98ad-b96b578c2943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁this',\n",
              " '▁is',\n",
              " '▁the',\n",
              " '▁first',\n",
              " '▁sentence',\n",
              " '</s>',\n",
              " '▁this',\n",
              " '▁is',\n",
              " '▁the',\n",
              " '▁second',\n",
              " '▁sentence',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        text=example[\"sentence_answer\"], \n",
        "        text_target=example[\"question\"],\n",
        "        truncation=True\n",
        "    )"
      ],
      "metadata": {
        "id": "gP0iFc0Lm2o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "f76d008f29c244568d8cae0c93162d0a",
            "031ab5cd22bd4ad5a752d68d042c9feb",
            "7bc5cfd68c624e33894aa592f7c553c7",
            "262db55c3a3a4b0e9dcf5a6b414b1971",
            "1179608a014847559efb3ab1ef285bb0",
            "644a6efb7ece4df2a6ff959520f30d8c",
            "9c1f1ea9445e472aa2af4fcfa053ad7e",
            "87e5c27ff24f4f2e97efc292a5e42c85",
            "6a4a2ebc16ac4e3189796ce691921989",
            "0d48f22042cb447298ca50b1376b855f",
            "ad1b687491934eb9b6ce1bbc7b1c8f3b",
            "fa5913127fa947848288a7041007a0ec",
            "27b6e64ac8f345e8a7dd116c6e58b752",
            "e544b40993fc4124b6a90278ca9c980a",
            "39f211468fea4aa4a08770b7c9bf2653",
            "df6b9d6b6163451bb82f44c2b94e4c33",
            "ac7e611399de44a3bde37379caecf99c",
            "3983ba42251741bf9dbd84e0c6eebc01",
            "9350d2518e1e4e2088f163fed0976b72",
            "7832d55edb694132af5b56f2c864fe0b",
            "10f7f5990d224bc5936f847979f67598",
            "d74748499b1f4d7fb5c0e2444082ba4e",
            "6dea78ccd64b4c84b1ab70348d56d37f",
            "106fec184be54b25970e7e9f466fee59",
            "38a3cfc23ce84fb19886dee129176ab8",
            "4dc1d3d43f514315a97e586ca4d055c1",
            "abccacaaa1b74757b17938498db2848d",
            "032b8f29caf44a80bd3ed6d8b6e718fc",
            "b81a6dae8ba149afb42938ac129482a9",
            "219e6189258c4190bedab2d06c9504a5",
            "50fb956b9a26493c840cbd5c746be5e0",
            "c5ee86b8a2e842019f96849f4b01a7a9",
            "0d3c6d3bdf3b4b23be55f33d88ba0e95"
          ]
        },
        "id": "7zLQBUDpngN-",
        "outputId": "2f80a8de-b0b3-4ea5-bf2d-faa1f3db3bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/76 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f76d008f29c244568d8cae0c93162d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa5913127fa947848288a7041007a0ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dea78ccd64b4c84b1ab70348d56d37f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['answer', 'question', 'sentence', 'paragraph', 'sentence_answer', 'paragraph_answer', 'paragraph_sentence', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 75722\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['answer', 'question', 'sentence', 'paragraph', 'sentence_answer', 'paragraph_answer', 'paragraph_sentence', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['answer', 'question', 'sentence', 'paragraph', 'sentence_answer', 'paragraph_answer', 'paragraph_sentence', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11877\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-tuning with trainer API"
      ],
      "metadata": {
        "id": "SslPzrKk9lYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub"
      ],
      "metadata": {
        "id": "hi3afj-z-Kh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "et6k0-f19oIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size=32\n",
        "nb_train_epochs=10\n",
        "\n",
        "# Show the training loss at end of every epoch.\n",
        "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = checkpoint.split(\"/\")[-1]\n",
        "print(model_name)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=nb_train_epochs,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "qFSmrFZ0_IzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "M1z3f60bN4kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "Ex-gdx03N53W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "id": "hTE9YMAjOAyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # print(f\"predictions: \\n{predictions}\")\n",
        "    # Decode the generated question into text.\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # print(f\"decoded_preds: \\n{decoded_preds}\")\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels!=-100, labels, tokenizer.pad_token_id)\n",
        "    # print(f\"labels: \\n{labels}\")\n",
        "    # Decode the reference questions into text.\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_labels = [[decoded_label] for decoded_label in decoded_labels]\n",
        "    # print(f\"decoded_labels: \\n{decoded_labels}\")\n",
        "    # Compute BLEU scores.\n",
        "    result = bleu_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "    # print(f\"result: {result}\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "Oy6ZEvzJBSEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq"
      ],
      "metadata": {
        "id": "7bvLomnBog2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "id": "JrV30bwLou4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "beeT4-0J0oHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pWXWlmonTjB8",
        "outputId": "72e7ce80-1651-45ba-9d57-1a7e848973c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 75722\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 23670\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23670' max='23670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23670/23670 1:59:57, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Precisions</th>\n",
              "      <th>Brevity Penalty</th>\n",
              "      <th>Length Ratio</th>\n",
              "      <th>Translation Length</th>\n",
              "      <th>Reference Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.913100</td>\n",
              "      <td>1.895996</td>\n",
              "      <td>0.186059</td>\n",
              "      <td>[0.5106522785325583, 0.24527605096325475, 0.15213089101620028, 0.09826831888082575]</td>\n",
              "      <td>0.894432</td>\n",
              "      <td>0.899631</td>\n",
              "      <td>108052</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.849000</td>\n",
              "      <td>1.880572</td>\n",
              "      <td>0.184930</td>\n",
              "      <td>[0.5080246970549962, 0.24224047124755838, 0.1501267012945318, 0.09769844997651479]</td>\n",
              "      <td>0.897198</td>\n",
              "      <td>0.902137</td>\n",
              "      <td>108353</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.816800</td>\n",
              "      <td>1.872697</td>\n",
              "      <td>0.185390</td>\n",
              "      <td>[0.5098220476080425, 0.24339941601352388, 0.15093927730223472, 0.09804485712417446]</td>\n",
              "      <td>0.895563</td>\n",
              "      <td>0.900655</td>\n",
              "      <td>108175</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.792300</td>\n",
              "      <td>1.869982</td>\n",
              "      <td>0.186255</td>\n",
              "      <td>[0.5133830790362698, 0.24615653748790878, 0.15267642711989654, 0.09868749835608512]</td>\n",
              "      <td>0.891631</td>\n",
              "      <td>0.897100</td>\n",
              "      <td>107748</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.774800</td>\n",
              "      <td>1.868894</td>\n",
              "      <td>0.186901</td>\n",
              "      <td>[0.5141749342160318, 0.24699161674176884, 0.1534446643289472, 0.0998958319598096]</td>\n",
              "      <td>0.889794</td>\n",
              "      <td>0.895443</td>\n",
              "      <td>107549</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.758700</td>\n",
              "      <td>1.869837</td>\n",
              "      <td>0.186411</td>\n",
              "      <td>[0.5146328972484753, 0.24659953524399691, 0.1532201031824242, 0.09970271520116271]</td>\n",
              "      <td>0.888370</td>\n",
              "      <td>0.894161</td>\n",
              "      <td>107395</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.746800</td>\n",
              "      <td>1.868036</td>\n",
              "      <td>0.186049</td>\n",
              "      <td>[0.5112671501824734, 0.24460144371064352, 0.15145530742292898, 0.09809866056844169]</td>\n",
              "      <td>0.896114</td>\n",
              "      <td>0.901155</td>\n",
              "      <td>108235</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.737800</td>\n",
              "      <td>1.866960</td>\n",
              "      <td>0.187567</td>\n",
              "      <td>[0.5122261914652045, 0.24610537728997678, 0.15275308797724588, 0.09927828458817849]</td>\n",
              "      <td>0.897014</td>\n",
              "      <td>0.901971</td>\n",
              "      <td>108333</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.731200</td>\n",
              "      <td>1.867626</td>\n",
              "      <td>0.187558</td>\n",
              "      <td>[0.5117292997446746, 0.24587669400218548, 0.15249172858304044, 0.0989853996535511]</td>\n",
              "      <td>0.898446</td>\n",
              "      <td>0.903270</td>\n",
              "      <td>108489</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.727100</td>\n",
              "      <td>1.866812</td>\n",
              "      <td>0.187299</td>\n",
              "      <td>[0.5110525491352382, 0.245362761211552, 0.15215077757561193, 0.09884530767928974]</td>\n",
              "      <td>0.898794</td>\n",
              "      <td>0.903586</td>\n",
              "      <td>108527</td>\n",
              "      <td>120107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-500/spiece.model\n",
            "tokenizer config file saved in t5-small-squad-finetuned/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-1000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-1000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-1000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-1000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-1500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-1500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-1500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-1500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-2000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-2000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-2000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-2000/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5106522785325583, 0.24527605096325475, 0.15213089101620028, 0.09826831888082575]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-2500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-2500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-2500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-2500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-3000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-3000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-3000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-3000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-3500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-3500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-3500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-3500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-4000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-4000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-4000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-4000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-4500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-4500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-4500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-4500/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5080246970549962, 0.24224047124755838, 0.1501267012945318, 0.09769844997651479]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-5000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-5000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-5000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-5000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-5500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-5500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-5500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-5500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-6000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-6000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-6000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-6000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-6500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-6500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-6500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-6500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-7000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-7000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-7000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-7000/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5098220476080425, 0.24339941601352388, 0.15093927730223472, 0.09804485712417446]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-7500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-7500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-7500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-7500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-8000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-8000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-8000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-8000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-8500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-8500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-8500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-8500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-9000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-9000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-9000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-9000/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5133830790362698, 0.24615653748790878, 0.15267642711989654, 0.09868749835608512]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-9500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-9500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-9500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-9500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-10000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-10000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-10000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-10000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-10500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-10500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-10500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-10500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-11000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-11000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-11000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-11000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-11500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-11500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-11500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-11500/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5141749342160318, 0.24699161674176884, 0.1534446643289472, 0.0998958319598096]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-12000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-12000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-12000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-12000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-12500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-12500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-12500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-12500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-13000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-13000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-13000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-13000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-13500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-13500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-13500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-13500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-14000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-14000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-14000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-14000/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5146328972484753, 0.24659953524399691, 0.1532201031824242, 0.09970271520116271]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-14500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-14500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-14500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-14500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-15000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-15000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-15000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-15000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-15500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-15500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-15500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-15500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-16000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-16000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-16000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-16000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-16500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-16500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-16500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-16500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-16500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-16500/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5112671501824734, 0.24460144371064352, 0.15145530742292898, 0.09809866056844169]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-17000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-17000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-17000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-17000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-17000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-17000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-17500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-17500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-17500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-17500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-17500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-17500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-18000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-18000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-18000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-18000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-18000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-18000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-18500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-18500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-18500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-18500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-18500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-18500/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5122261914652045, 0.24610537728997678, 0.15275308797724588, 0.09927828458817849]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-19000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-19000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-19000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-19000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-19000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-19000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-19500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-19500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-19500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-19500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-19500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-19500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-20000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-20000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-20000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-20000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-20000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-20000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-20500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-20500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-20500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-20500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-20500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-20500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-21000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-21000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-21000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-21000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-21000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-21000/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5117292997446746, 0.24587669400218548, 0.15249172858304044, 0.0989853996535511]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-21500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-21500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-21500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-21500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-21500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-21500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-22000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-22000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-22000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-22000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-22000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-22000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-22500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-22500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-22500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-22500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-22500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-22500/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-23000\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-23000/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-23000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-23000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-23000/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-23000/spiece.model\n",
            "Saving model checkpoint to t5-small-squad-finetuned/checkpoint-23500\n",
            "Configuration saved in t5-small-squad-finetuned/checkpoint-23500/config.json\n",
            "Model weights saved in t5-small-squad-finetuned/checkpoint-23500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-squad-finetuned/checkpoint-23500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-squad-finetuned/checkpoint-23500/special_tokens_map.json\n",
            "Copy vocab file to t5-small-squad-finetuned/checkpoint-23500/spiece.model\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence. If paragraph_sentence, question, sentence_answer, paragraph, answer, paragraph_answer, sentence are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10570\n",
            "  Batch size = 32\n",
            "Trainer is attempting to log a value of \"[0.5110525491352382, 0.245362761211552, 0.15215077757561193, 0.09884530767928974]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=23670, training_loss=1.7847247747011108, metrics={'train_runtime': 7200.3933, 'train_samples_per_second': 105.164, 'train_steps_per_second': 3.287, 'total_flos': 2.3301590188621824e+16, 'train_loss': 1.7847247747011108, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "swqd9w5T4sKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Use this code segment to zip and download the directly from Colab to your local machine.\n",
        "\"\"\"\n",
        "# !zip -r \"t5-small-squad-finetuned.zip\" t5-small-squad-finetuned\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"t5-small-squad-finetuned.zip\")"
      ],
      "metadata": {
        "id": "TQ-i3uPXlwDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f1c59e25-8464-4bfb-d48a-ccffd7f968fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nUse this code segment to zip and download the directly from Colab to your local machine.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89rwVL1h6Y87"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}